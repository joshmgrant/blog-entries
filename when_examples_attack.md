Picking the right examples matter. Google recently learned that they matter quite a bit.

In the past I've written about [writing code samples](https://simplythetest.tumblr.com/post/612302779439087616/writing-example-code-a-series) and some good practices (I think) to follow. These include [knowing your audience](https://simplythetest.tumblr.com/post/612751899042742272/writing-example-code-knowing-your-audience-or) and [keeping your examples up to date](https://simplythetest.tumblr.com/post/620507010419556352/writing-example-code-keeping-up-appearances-and). Having good examples of what your code - or product - can do is essential for getting some attention in a competitive marketplace. 

I suppose I should've mentioned that your code examples should be accurate and have outputs that are correct but I assumed that was obvious.

This week, Google [announced](https://www.reuters.com/technology/google-ai-chatbot-bard-offers-inaccurate-information-company-ad-2023-02-08/) a new AI chatbot called Bard. This chatbot could answer all sorts of questions in the same manner as the previously announced ChatGPT. However, in Google's ads they decided to use an example of Bard answering a question about the first images taken in space. This resulted in an response that was factually incorrect. Not a good look for an AI chat assistant. As a result, Google lost billions in trading.

When I read this story about Google's unfortunate ad choice my first thought was something along the lines of "why didn't anyone _test_ this example?". Even one person validating the ad copy and fact checking before going live could've caught this. So perhaps this illustrates an additional good practice for sample code:

Test your example code to make sure it works expected.

This kind of advice might just prevent a costly billion dollar mistake.