Lately I've noticed on Twitter and elsewhere a lot of folks dunking on teams and organziations that only have/do overly extensive UI automated testing. In keeping with my [resolution to stop bashing UI automation in general](http://simplythetest.tumblr.com/post/170854194200/giving-up-some-things), I thought I'd discuss a few *good* reasons why some teams have only UI automated testing.

First, blanket disclaimer: _Generally speaking, following the [automated test pyramid](http://blog.goneopen.com/2010/08/test-automation-pyramid-review/) (many unit tests, lots of service/integration layer tests, small number of UI tests), is a good practice that I support. Write automated tests at the appropriate level where possible._

Here are some situations where teams are writing only/mostly UI automated and that's ok: 

**Getting Buy-In into Automation**: In some cases, some individuals on teams are hesitant to start automation or automated testing. Perhaps managers are concerned the benefits will outweigh the costs based on a team's capabilities or priorities. Sometimes developers don't truly understand how automated testing will help at all. One good thing about UI automation is that it's easy to undersand and easy to see, even for non-technical team members. With a few keystrokes or a click of a button, your application opens up and _voila_ your app is being exercised. Computers can walk through test scenarios faster and more efficiently than testers, and won't get bored or disengaged. When those hestiatnt inviduals *see* UI automation in action, they might start to *get it* and buy-in to automated testing. While not a difficult technical problem, this is a significant people problem: sometimes convincing a manager or senior individual to agree to giving automation at try is just as difficult as writing a first acceptance test. 

In my case I've worked a on a team that previously had no test automation (none!). The team's director at the time convinced executives to give test automation a chance by showing some Protractor-based UI tests. The execs were impressed and test automation got the green light. Showing unit tests for various front-end or backend components likely wouldn't have had the same impact, even if they are a better practice. Eventually this team would be well on its way to having strong continuous deployment practices and automated tests across the whole test pyramid.

**UI Tests as Evolution**: Building a piece of software is less of a sprint as it is a marthon. Developing a piece of software is an evolutionary process where teams adapt (or don't) as the nature of the project changes. Introducting test automation into a a project is like any other change. The team will adapt to having test automation as part of their work. In larger orgs this means having a central team develop test automation for other teams or it may mean creating such a team. Due to a variety of factors, this means that some teams have only/mainly UI test automation. UI test automation tends to be infrastructure-heavy, and merely getting tests in place can require significant work. This is one reason why some orgs focus so much on UI automation. Another is evoling skill sets. Sometimes getting started with UI automation is conceptually easier for teams than other forms of automated testing. I've seen great success with integration tests that test business logic and several features working together, but even _describing_ and _justifying_ such tests was difficult for me while UI tests were not. 

This reason can follow along similar lines as the buy-in reason. Often teams that need some buy-in are also on a path toward improving their software practices in other ways in addition to having automated tests. 

**Organizational Dysfunction**: The test pyramid does not take into account organizational dynamics. In some orgs, different teams own different aspects of the software product, which sometimes includes ownership of test automation. In a perfect world, developers would write the bulk of automated tests all levels since test code is production code, with testers or test automation specalists sometimes stepping in to help when needed. Of course, we do not live in a perfect world. This may lead to good people doing bad practices, even if they have a feeling the practices are bad. One place I worked tasked the test development team to write server-side "unit tests" that were more like service tests. This wasn't really optimal but it was the way it was. In many places teams are heavily siloed from one another, creating communication breakdowns or misunderstandings. Since test automation often touches on several aspects of an app, including deployment or build processes, development, testing and operations, these silos can create suboptimal situations. UI automation often arises out of this either a way for automated tests to "catch" any "mistakes" other teams make or as good practice implemented poorly. In this case, test developers could be doing excellent work with UI automation or at least doing better than they were without it.

I should also mention that there is clearly some overlap between these situations. 

Take a minute to consider these situations before writing your next "UI automation sucks" post.

