Scaling is all the rage in software development and tech these days. Every company or project wants to scale up, be Google-scale, scale faster or simiar. But scaling is difficult, and some things scale better than others. 

For example, John D Cook points out that [stupidity scales](http://www.johndcook.com/blog/2010/07/19/stupidity-scales/). His post is slightly old but I think it's more valid than ever. Often times it's easier to pick a dumb thing that can work in many contexts and scale it up than a bettter thing that only works in a few contexts. In John's words, "[w]e can’t use common sense because it doesn’t fit on a form." 

I've been thinking about this post for a while, and I think it's good but slightly incomplete. My opinion is: 

> Stupidily scales easily. Smart scales difficultly.

Scaling up a smart process can be done but it can be challening. This is - in part - the central problem of Continuous Deployment/Delivery. In this case, processes and infrastructure need to be built in a way that facilitates good practices and good end products smoothly as possible. Good process can really help speed things up, make it easy to do the right things and difficult or impossible to do the wrong things (loosely speaking).

One of the biggest changes in software development and potentially much farther beyond is how [quickly tooling has changed recently](http://simplythetest.tumblr.com/post/151484057075/brief-thoughts-on-the-pace-of-change-in-software). Tools and processes once only available to large dedicated software companies are becoming available to pracitically anyone with a laptop and decent network connection. I'm wondering if these ideas will carry over to more general settings as they become more accessible. In that case, scaling up smart things will be even more of a priority.